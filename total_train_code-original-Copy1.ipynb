{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eac8cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sclab6/anaconda3/envs/test/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # eps is a small value added to the variance to avoid divide-by-zero.\n",
    "    size = feat.size()\n",
    "    assert (len(size) == 4)\n",
    "    N, C = size[:2]\n",
    "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
    "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
    "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "\n",
    "def adaptive_instance_normalization(content_feat, style_feat):\n",
    "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
    "    size = content_feat.size()\n",
    "    style_mean, style_std = calc_mean_std(style_feat)\n",
    "    content_mean, content_std = calc_mean_std(content_feat)\n",
    "\n",
    "    normalized_feat = (content_feat - content_mean.expand(\n",
    "        size)) / content_std.expand(size)\n",
    "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n",
    "\n",
    "\n",
    "def _calc_feat_flatten_mean_std(feat):\n",
    "    # takes 3D feat (C, H, W), return mean and std of array within channels\n",
    "    assert (feat.size()[0] == 3)\n",
    "    assert (isinstance(feat, torch.FloatTensor))\n",
    "    feat_flatten = feat.view(3, -1)\n",
    "    mean = feat_flatten.mean(dim=-1, keepdim=True)\n",
    "    std = feat_flatten.std(dim=-1, keepdim=True)\n",
    "    return feat_flatten, mean, std\n",
    "\n",
    "\n",
    "def _mat_sqrt(x):\n",
    "    U, D, V = torch.svd(x)\n",
    "    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n",
    "\n",
    "\n",
    "def coral(source, target):\n",
    "    # assume both source and target are 3D array (C, H, W)\n",
    "    # Note: flatten -> f\n",
    "\n",
    "    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n",
    "    source_f_norm = (source_f - source_f_mean.expand_as(\n",
    "        source_f)) / source_f_std.expand_as(source_f)\n",
    "    source_f_cov_eye = \\\n",
    "        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n",
    "    target_f_norm = (target_f - target_f_mean.expand_as(\n",
    "        target_f)) / target_f_std.expand_as(target_f)\n",
    "    target_f_cov_eye = \\\n",
    "        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n",
    "\n",
    "    source_f_norm_transfer = torch.mm(\n",
    "        _mat_sqrt(target_f_cov_eye),\n",
    "        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n",
    "                 source_f_norm)\n",
    "    )\n",
    "\n",
    "    source_f_transfer = source_f_norm_transfer * \\\n",
    "                        target_f_std.expand_as(source_f_norm) + \\\n",
    "                        target_f_mean.expand_as(source_f_norm)\n",
    "\n",
    "    return source_f_transfer.view(source.size())\n",
    "\n",
    "def rgb_to_yiq(img): # img shape - batch size channel width height\n",
    "    bsz, ch, w, h = img.shape\n",
    "    yiq_from_rgb = torch.Tensor([[0.299,      0.587,        0.114],\n",
    "                                 [0.59590059, -0.27455667, -0.32134392],\n",
    "                                 [0.21153661, -0.52273617, 0.31119955]]).cuda()\n",
    "\n",
    "    out = img.permute(1,0,2,3).reshape(ch, -1)\n",
    "    out = torch.matmul(yiq_from_rgb, out)\n",
    "    out = out.reshape(ch, bsz, w, h).permute(1,0,2,3)\n",
    "    return out\n",
    "\n",
    "def yiq_to_rgb(img):\n",
    "    bsz, ch, w, h = img.shape\n",
    "    yiq_from_rgb = torch.Tensor([[0.299,      0.587,        0.114],\n",
    "                                 [0.59590059, -0.27455667, -0.32134392],\n",
    "                                 [0.21153661, -0.52273617, 0.31119955]]).cuda()\n",
    "    rgb_from_yiq = torch.inverse(yiq_from_rgb)\n",
    "    out = img.permute(1,0,2,3).reshape(ch, -1)\n",
    "    out = torch.matmul(rgb_from_yiq, out)\n",
    "    out = out.reshape(ch, bsz, w, h).permute(1,0,2,3)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e0197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "\n",
    "class RGBuvHistBlock(nn.Module):\n",
    "    def __init__(self, h=64, insz=150, resizing='interpolation',\n",
    "               method='inverse-quadratic', sigma=0.02, intensity_scale=True,\n",
    "               hist_boundary=None, green_only=False, device='cuda'):\n",
    "        super(RGBuvHistBlock, self).__init__()\n",
    "        self.h = h\n",
    "        self.insz = insz\n",
    "        self.device = device\n",
    "        self.resizing = resizing\n",
    "        self.method = method\n",
    "        self.intensity_scale = intensity_scale\n",
    "        self.green_only = green_only\n",
    "        if hist_boundary is None:\n",
    "            hist_boundary = [-3, 3]\n",
    "        hist_boundary.sort()\n",
    "        self.hist_boundary = hist_boundary\n",
    "        if self.method == 'thresholding':\n",
    "            self.eps = (abs(hist_boundary[0]) + abs(hist_boundary[1])) / h\n",
    "        else:\n",
    "            self.sigma = sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.clamp(x, 0, 1)\n",
    "        if x.shape[2] > self.insz or x.shape[3] > self.insz:\n",
    "            if self.resizing == 'interpolation':\n",
    "                x_sampled = F.interpolate(x, size=(self.insz, self.insz),\n",
    "                                  mode='bilinear', align_corners=False)\n",
    "            elif self.resizing == 'sampling':\n",
    "                inds_1 = torch.LongTensor(\n",
    "              np.linspace(0, x.shape[2], self.h, endpoint=False)).to(\n",
    "              device=self.device)\n",
    "                inds_2 = torch.LongTensor(\n",
    "              np.linspace(0, x.shape[3], self.h, endpoint=False)).to(\n",
    "              device=self.device)\n",
    "                x_sampled = x.index_select(2, inds_1)\n",
    "                x_sampled = x_sampled.index_select(3, inds_2)\n",
    "            else:\n",
    "                raise Exception(\n",
    "              f'Wrong resizing method. It should be: interpolation or sampling. '\n",
    "              f'But the given value is {self.resizing}.')\n",
    "        else:\n",
    "            x_sampled = x\n",
    "\n",
    "        L = x_sampled.shape[0]  # size of mini-batch\n",
    "        if x_sampled.shape[1] > 3:\n",
    "            x_sampled = x_sampled[:, :3, :, :]\n",
    "        X = torch.unbind(x_sampled, dim=0)\n",
    "        hists = torch.zeros((x_sampled.shape[0], 1 + int(not self.green_only) * 2,\n",
    "                         self.h, self.h)).to(device=self.device)\n",
    "        for l in range(L):\n",
    "            I = torch.t(torch.reshape(X[l], (3, -1)))\n",
    "            II = torch.pow(I, 2)\n",
    "            if self.intensity_scale:\n",
    "                Iy = torch.unsqueeze(torch.sqrt(II[:, 0] + II[:, 1] + II[:, 2] + EPS),\n",
    "                             dim=1)\n",
    "            else:\n",
    "                Iy = 1\n",
    "            if not self.green_only:\n",
    "                Iu0 = torch.unsqueeze(torch.log(I[:, 0] + EPS) - torch.log(I[:, 1] +\n",
    "                                                                       EPS), dim=1)\n",
    "                Iv0 = torch.unsqueeze(torch.log(I[:, 0] + EPS) - torch.log(I[:, 2] +\n",
    "                                                                       EPS), dim=1)\n",
    "                diff_u0 = abs(\n",
    "              Iu0 - torch.unsqueeze(torch.tensor(np.linspace(\n",
    "                self.hist_boundary[0], self.hist_boundary[1], num=self.h)),\n",
    "                dim=0).to(self.device))\n",
    "                diff_v0 = abs(\n",
    "              Iv0 - torch.unsqueeze(torch.tensor(np.linspace(\n",
    "                self.hist_boundary[0], self.hist_boundary[1], num=self.h)),\n",
    "                dim=0).to(self.device))\n",
    "            \n",
    "                if self.method == 'thresholding':\n",
    "                    diff_u0 = torch.reshape(diff_u0, (-1, self.h)) <= self.eps / 2\n",
    "                    diff_v0 = torch.reshape(diff_v0, (-1, self.h)) <= self.eps / 2\n",
    "                elif self.method == 'RBF':\n",
    "                    diff_u0 = torch.pow(torch.reshape(diff_u0, (-1, self.h)),\n",
    "                                  2) / self.sigma ** 2\n",
    "                    diff_v0 = torch.pow(torch.reshape(diff_v0, (-1, self.h)),\n",
    "                                  2) / self.sigma ** 2\n",
    "                    diff_u0 = torch.exp(-diff_u0)  # Radial basis function\n",
    "                    diff_v0 = torch.exp(-diff_v0)\n",
    "                elif self.method == 'inverse-quadratic':\n",
    "                    diff_u0 = torch.pow(torch.reshape(diff_u0, (-1, self.h)),\n",
    "                                  2) / self.sigma ** 2\n",
    "                    diff_v0 = torch.pow(torch.reshape(diff_v0, (-1, self.h)),\n",
    "                                  2) / self.sigma ** 2\n",
    "                    diff_u0 = 1 / (1 + diff_u0)  # Inverse quadratic\n",
    "                    diff_v0 = 1 / (1 + diff_v0)\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                f'Wrong kernel method. It should be either thresholding, RBF,'\n",
    "                f' inverse-quadratic. But the given value is {self.method}.')\n",
    "                diff_u0 = diff_u0.type(torch.float32)\n",
    "                diff_v0 = diff_v0.type(torch.float32)\n",
    "                a = torch.t(Iy * diff_u0)\n",
    "                hists[l, 0, :, :] = torch.mm(a, diff_v0)\n",
    "\n",
    "            Iu1 = torch.unsqueeze(torch.log(I[:, 1] + EPS) - torch.log(I[:, 0] + EPS),\n",
    "                                dim=1)\n",
    "            Iv1 = torch.unsqueeze(torch.log(I[:, 1] + EPS) - torch.log(I[:, 2] + EPS),\n",
    "                                dim=1)\n",
    "            diff_u1 = abs(\n",
    "            Iu1 - torch.unsqueeze(torch.tensor(np.linspace(\n",
    "              self.hist_boundary[0], self.hist_boundary[1], num=self.h)),\n",
    "              dim=0).to(self.device))\n",
    "            diff_v1 = abs(\n",
    "            Iv1 - torch.unsqueeze(torch.tensor(np.linspace(\n",
    "              self.hist_boundary[0], self.hist_boundary[1], num=self.h)),\n",
    "              dim=0).to(self.device))\n",
    "\n",
    "            if self.method == 'thresholding':\n",
    "                diff_u1 = torch.reshape(diff_u1, (-1, self.h)) <= self.eps / 2\n",
    "                diff_v1 = torch.reshape(diff_v1, (-1, self.h)) <= self.eps / 2\n",
    "            elif self.method == 'RBF':\n",
    "                diff_u1 = torch.pow(torch.reshape(diff_u1, (-1, self.h)),\n",
    "                                    2) / self.sigma ** 2\n",
    "                diff_v1 = torch.pow(torch.reshape(diff_v1, (-1, self.h)),\n",
    "                                    2) / self.sigma ** 2\n",
    "                diff_u1 = torch.exp(-diff_u1)  # Gaussian\n",
    "                diff_v1 = torch.exp(-diff_v1)\n",
    "            elif self.method == 'inverse-quadratic':\n",
    "                diff_u1 = torch.pow(torch.reshape(diff_u1, (-1, self.h)),\n",
    "                                    2) / self.sigma ** 2\n",
    "                diff_v1 = torch.pow(torch.reshape(diff_v1, (-1, self.h)),\n",
    "                                    2) / self.sigma ** 2\n",
    "                diff_u1 = 1 / (1 + diff_u1)  # Inverse quadratic\n",
    "                diff_v1 = 1 / (1 + diff_v1)\n",
    "\n",
    "            diff_u1 = diff_u1.type(torch.float32)\n",
    "            diff_v1 = diff_v1.type(torch.float32)\n",
    "            a = torch.t(Iy * diff_u1)\n",
    "            if not self.green_only:\n",
    "                hists[l, 1, :, :] = torch.mm(a, diff_v1)\n",
    "            else:\n",
    "                hists[l, 0, :, :] = torch.mm(a, diff_v1)\n",
    "\n",
    "            if not self.green_only:\n",
    "                Iu2 = torch.unsqueeze(torch.log(I[:, 2] + EPS) - torch.log(I[:, 0] +\n",
    "                                                                           EPS), dim=1)\n",
    "                Iv2 = torch.unsqueeze(torch.log(I[:, 2] + EPS) - torch.log(I[:, 1] +\n",
    "                                                                           EPS), dim=1)\n",
    "                diff_u2 = abs(\n",
    "                  Iu2 - torch.unsqueeze(torch.tensor(np.linspace(\n",
    "                    self.hist_boundary[0], self.hist_boundary[1], num=self.h)),\n",
    "                    dim=0).to(self.device))\n",
    "                diff_v2 = abs(\n",
    "                  Iv2 - torch.unsqueeze(torch.tensor(np.linspace(\n",
    "                    self.hist_boundary[0], self.hist_boundary[1], num=self.h)),\n",
    "                    dim=0).to(self.device))\n",
    "                if self.method == 'thresholding':\n",
    "                    diff_u2 = torch.reshape(diff_u2, (-1, self.h)) <= self.eps / 2\n",
    "                    diff_v2 = torch.reshape(diff_v2, (-1, self.h)) <= self.eps / 2\n",
    "                elif self.method == 'RBF':\n",
    "                    diff_u2 = torch.pow(torch.reshape(diff_u2, (-1, self.h)),\n",
    "                                      2) / self.sigma ** 2\n",
    "                    diff_v2 = torch.pow(torch.reshape(diff_v2, (-1, self.h)),\n",
    "                                      2) / self.sigma ** 2\n",
    "                    diff_u2 = torch.exp(-diff_u2)  # Gaussian\n",
    "                    diff_v2 = torch.exp(-diff_v2)\n",
    "                elif self.method == 'inverse-quadratic':\n",
    "                    diff_u2 = torch.pow(torch.reshape(diff_u2, (-1, self.h)),\n",
    "                                      2) / self.sigma ** 2\n",
    "                    diff_v2 = torch.pow(torch.reshape(diff_v2, (-1, self.h)),\n",
    "                                      2) / self.sigma ** 2\n",
    "                    diff_u2 = 1 / (1 + diff_u2)  # Inverse quadratic\n",
    "                    diff_v2 = 1 / (1 + diff_v2)\n",
    "                diff_u2 = diff_u2.type(torch.float32)\n",
    "                diff_v2 = diff_v2.type(torch.float32)\n",
    "                a = torch.t(Iy * diff_u2)\n",
    "                hists[l, 2, :, :] = torch.mm(a, diff_v2)\n",
    "\n",
    "        # normalization\n",
    "        hists_normalized = hists / (\n",
    "            ((hists.sum(dim=1)).sum(dim=1)).sum(dim=1).view(-1, 1, 1, 1) + EPS)\n",
    "\n",
    "        return hists_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db39365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# from function import adaptive_instance_normalization as adain\n",
    "# from function import calc_mean_std\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "\n",
    "\n",
    "class HistVectorizer(nn.Module):\n",
    "    def __init__(self, insize, emb, depth):\n",
    "        super().__init__()\n",
    "        self.flatten = Flatten()\n",
    "        fc_layers = []\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                fc_layers.extend(\n",
    "                  [nn.Linear(insize * insize * 3, emb * 2), nn.LeakyReLU(0.2, inplace=True)])\n",
    "            elif i == 1:\n",
    "                fc_layers.extend([nn.Linear(emb * 2, emb), nn.LeakyReLU(0.2, inplace=True)])\n",
    "            else:\n",
    "                fc_layers.extend([nn.Linear(emb, emb), nn.LeakyReLU(0.2, inplace=True)])\n",
    "        self.fcs = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fcs(self.flatten(x))\n",
    "\n",
    "class Conv2DMod(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, kernel, demod=True, stride=1,\n",
    "               dilation=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.filters = out_chan\n",
    "        self.demod = demod\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.weight = nn.Parameter(torch.randn((out_chan, in_chan, kernel, kernel)))\n",
    "        nn.init.kaiming_normal_(self.weight, a=0, mode='fan_in',\n",
    "                                nonlinearity='leaky_relu')\n",
    "\n",
    "    def _get_same_padding(self, size, kernel, dilation, stride):\n",
    "        return ((size - 1) * (stride - 1) + dilation * (kernel - 1)) // 2\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        w1 = y[:, None, :, None, None]\n",
    "        w2 = self.weight[None, :, :, :, :]\n",
    "        weights = w2 * (w1 + 1)\n",
    "\n",
    "        if self.demod:\n",
    "            d = torch.rsqrt((weights ** 2).sum(dim=(2, 3, 4), keepdim=True) + EPS)\n",
    "            weights = weights * d\n",
    "\n",
    "        x = x.reshape(1, -1, h, w)\n",
    "\n",
    "        _, _, *ws = weights.shape\n",
    "        weights = weights.reshape(b * self.filters, *ws)\n",
    "\n",
    "        padding = self._get_same_padding(h, self.kernel, self.dilation, self.stride)\n",
    "        x = F.conv2d(x, weights, padding=padding, groups=b)\n",
    "\n",
    "        x = x.reshape(-1, self.filters, h, w)\n",
    "        return x\n",
    "\n",
    "class RGBBlock(nn.Module):\n",
    "    def __init__(self, latent_dim, input_channel, upsample, rgba=False):\n",
    "        super().__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.to_style = nn.Linear(latent_dim, input_channel)\n",
    "\n",
    "        out_filters = input_channel#3 if not rgba else 4\n",
    "        self.conv = Conv2DMod(input_channel, out_filters, 1, demod=False)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear',\n",
    "                                    align_corners=False) if upsample else None\n",
    "\n",
    "    def forward(self, x, color):\n",
    "        style = self.to_style(color)\n",
    "        x = self.conv(x, style)\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            x = self.upsample(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# decoder1 = nn.Sequential(\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(512, 256, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     RGBBlock(512, 256, True),\n",
    "#     #nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(256, 256, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(256, 256, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     RGBBlock(512, 256, False),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(256, 256, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(256, 128, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     RGBBlock(512, 128, True),\n",
    "#     #nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(128, 128, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(128, 64, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     RGBBlock(512, 64, True),\n",
    "#     #nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(64, 64, (3, 3)),\n",
    "#     nn.LeakyReLU(0.2),\n",
    "#     nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "#     nn.Conv2d(64, 3, (3, 3)),\n",
    "# )\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.padding = nn.ReflectionPad2d((1, 1, 1, 1))\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.conv1 = nn.Conv2d(512*2, 256, (3, 3))\n",
    "        #self.rgb1 = RGBBlock(512, 256, True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(256, 256, (3, 3))\n",
    "        #self.rgb2 = RGBBlock(512, 256, False)\n",
    "        self.conv3 = nn.Conv2d(256, 256, (3, 3))\n",
    "        #self.rgb3 = RGBBlock(512, 256, False)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 256, (3, 3))\n",
    "        #self.rgb4 = RGBBlock(512, 256, False)\n",
    "        self.conv5 = nn.Conv2d(2*256, 128, (3, 3))\n",
    "        #self.rgb5 = RGBBlock(512, 128, True)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(128, 128, (3, 3))\n",
    "        #self.rgb6 = RGBBlock(512, 128, False)\n",
    "        self.conv7 = nn.Conv2d(2*128, 64, (3, 3))\n",
    "        #self.rgb7 = RGBBlock(512, 64, True)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(64, 64, (3, 3))\n",
    "        #self.rgb8 = RGBBlock(512, 64, False)\n",
    "        self.final_conv = nn.Conv2d(2*64, 3, (3, 3))\n",
    "        #self.final_rgb = RGBBlock(512, 3, False)\n",
    "\n",
    "    def forward(self, x, hist):\n",
    "        x = torch.cat((x, hist[3]),dim=1)\n",
    "        x = self.leaky_relu(self.conv1(self.padding(x)))\n",
    "        x = self.upsample(x)\n",
    "        x = self.leaky_relu(self.conv2(self.padding(x)))\n",
    "        x = self.leaky_relu(self.conv3(self.padding(x)))\n",
    "        x = self.leaky_relu(self.conv4(self.padding(x)))\n",
    "        x = torch.cat((x, hist[2]),dim=1)\n",
    "        x = self.leaky_relu(self.conv5(self.padding(x)))\n",
    "        x = self.upsample(x)\n",
    "        x = self.leaky_relu(self.conv6(self.padding(x)))\n",
    "        x = torch.cat((x, hist[1]),dim=1)\n",
    "        x = self.leaky_relu(self.conv7(self.padding(x)))\n",
    "        x = self.upsample(x)\n",
    "        x = self.leaky_relu(self.conv8(self.padding(x)))\n",
    "        x = torch.cat((x,hist[0]),dim=1)\n",
    "        x = self.final_conv(self.padding(x))\n",
    "        return x\n",
    "\n",
    "vgg = nn.Sequential(\n",
    "    nn.Conv2d(3, 3, (1, 1)),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(3, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 64, (3, 3)),\n",
    "    nn.ReLU(),  # relu1-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(64, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 128, (3, 3)),\n",
    "    nn.ReLU(),  # relu2-2\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(128, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 256, (3, 3)),\n",
    "    nn.ReLU(),  # relu3-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(256, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-1, this is the last layer used\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu4-4\n",
    "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-1\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-2\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU(),  # relu5-3\n",
    "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "    nn.Conv2d(512, 512, (3, 3)),\n",
    "    nn.ReLU()  # relu5-4\n",
    ")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, encoder, decoder1, device):\n",
    "        super(Net, self).__init__()\n",
    "        enc_layers = list(encoder.children())\n",
    "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
    "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
    "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
    "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
    "        self.decoder = decoder1\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "        \n",
    "        self.his_block = histblock = RGBuvHistBlock(insz=150, h=64,\n",
    "                                    method='inverse-quadratic', resizing='sampling',\n",
    "                                    device=device)\n",
    "        self.his_block.requires_grad = False\n",
    "        #self.his_mapping_network = HistVectorizer(64, 512, int(8)).to(device)\n",
    "\n",
    "        # fix the encoder\n",
    "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
    "            for param in getattr(self, name).parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n",
    "    def encode_with_intermediate(self, input):\n",
    "        results = [input]\n",
    "        for i in range(4):\n",
    "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
    "            results.append(func(results[-1]))\n",
    "        return results[1:]\n",
    "\n",
    "    # extract relu4_1 from input image\n",
    "    def encode(self, input):\n",
    "        for i in range(4):\n",
    "            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n",
    "        return input\n",
    "\n",
    "    def calc_content_loss(self, input, target):\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        return self.mse_loss(input, target)\n",
    "\n",
    "    def calc_style_loss(self, input, target):\n",
    "        assert (input.size() == target.size())\n",
    "        assert (target.requires_grad is False)\n",
    "        input_mean, input_std = calc_mean_std(input)\n",
    "        target_mean, target_std = calc_mean_std(target)\n",
    "        return self.mse_loss(input_mean, target_mean) + \\\n",
    "               self.mse_loss(input_std, target_std)\n",
    "\n",
    "    def forward(self, content, style, color, alpha=1.0):\n",
    "        assert 0 <= alpha <= 1\n",
    "        \n",
    "        style_feats = self.encode_with_intermediate(style)\n",
    "        content_feat = self.encode(content)\n",
    "        color_feats = self.encode_with_intermediate(color)\n",
    "        his = self.his_block(color)\n",
    "        \n",
    "        tt = adaptive_instance_normalization(content_feat, style_feats[-1])\n",
    "\n",
    "        tt = alpha * tt + (1 - alpha) * content_feat\n",
    "\n",
    "        g_t = self.decoder(tt, color_feats)\n",
    "        g_t_feats = self.encode_with_intermediate(g_t)\n",
    "        g_t_his = self.his_block(g_t)\n",
    "        loss_ct = self.calc_content_loss(g_t_feats[-1], tt)\n",
    "        loss_st = self.calc_style_loss(g_t_feats[0], style_feats[0])\n",
    "        loss_sc = self.calc_style_loss(g_t_feats[0], color_feats[0])\n",
    "        \n",
    "        loss_color = (torch.sqrt(\n",
    "        torch.sum(\n",
    "          torch.pow(torch.sqrt(his) - torch.sqrt(g_t_his),\n",
    "                    2)))) / his.shape[0]\n",
    "        for i in range(1, 4):\n",
    "            loss_st += self.calc_style_loss(g_t_feats[i], style_feats[i])\n",
    "            loss_sc += self.calc_style_loss(g_t_feats[i], color_feats[i])\n",
    "        return loss_ct, loss_st, loss_sc, loss_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a02b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "def InfiniteSampler(n):\n",
    "    # i = 0\n",
    "    i = n - 1\n",
    "    order = np.random.permutation(n)\n",
    "    while True:\n",
    "        yield order[i]\n",
    "        i += 1\n",
    "        if i >= n:\n",
    "            np.random.seed()\n",
    "            order = np.random.permutation(n)\n",
    "            i = 0\n",
    "\n",
    "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.num_samples = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(InfiniteSampler(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return 2 ** 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa34eb56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start init\n",
      "create dataloader\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 160000/160000 [62:39:35<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageFile\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import net\n",
    "#from sampler import InfiniteSamplerWrapper\n",
    "\n",
    "cudnn.benchmark = True\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError\n",
    "# Disable OSError: image file is truncated\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def train_transform():\n",
    "    transform_list = [\n",
    "        transforms.Resize(size=(512, 512)),\n",
    "        transforms.RandomCrop(256),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "class FlatFolderDataset(data.Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        super(FlatFolderDataset, self).__init__()\n",
    "        self.root = root\n",
    "        self.paths = list(glob(self.root+'/*.jpg'))\n",
    "        random.shuffle(self.paths)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(str(path)).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def name(self):\n",
    "        return 'FlatFolderDataset'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, iteration_count):\n",
    "    \"\"\"Imitating the original implementation\"\"\"\n",
    "    lr = args.lr / (1.0 + args.lr_decay * iteration_count)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# Basic options\n",
    "parser.add_argument('--content_dir', default='./train2017', type=str,\n",
    "                    help='Directory path to a batch of content images')\n",
    "parser.add_argument('--style_dir', default='./data/images/*/*',\n",
    "                    help='Directory path to a batch of style images')\n",
    "parser.add_argument('--color_dir', default='./data/images/*/*',\n",
    "                    help='Directory path to a batch of style images')\n",
    "parser.add_argument('--vgg', type=str, default='models/vgg_normalised.pth')\n",
    "\n",
    "# training options\n",
    "parser.add_argument('--save_dir', default='./experiments/model1',\n",
    "                    help='Directory to save the model')\n",
    "parser.add_argument('--log_dir', default='./logs',\n",
    "                    help='Directory to save the log')\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--lr_decay', type=float, default=5e-5)\n",
    "parser.add_argument('--max_iter', type=int, default=160000)\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "parser.add_argument('--style_weight', type=float, default=5.0)\n",
    "parser.add_argument('--content_weight', type=float, default=1.0)\n",
    "parser.add_argument('--n_threads', type=int, default=0)\n",
    "parser.add_argument('--save_model_interval', type=int, default=10000)\n",
    "args = parser.parse_args([])\n",
    "print('start init')\n",
    "device = torch.device('cuda:1')\n",
    "save_dir = Path(args.save_dir)\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "log_dir = Path(args.log_dir)\n",
    "log_dir.mkdir(exist_ok=True, parents=True)\n",
    "writer = SummaryWriter(log_dir=str(log_dir))\n",
    "\n",
    "decoder = Decoder()\n",
    "vgg = vgg\n",
    "\n",
    "vgg.load_state_dict(torch.load(args.vgg))\n",
    "vgg = nn.Sequential(*list(vgg.children())[:31])\n",
    "network = Net(vgg, decoder, device)\n",
    "network.train()\n",
    "network.to(device)\n",
    "\n",
    "def convert_rgb_to_transparent(image):\n",
    "    if image.mode == 'RGB':\n",
    "        return image.convert('RGBA')\n",
    "    return image\n",
    "\n",
    "\n",
    "def convert_transparent_to_rgb(image):\n",
    "    if image.mode == 'RGBA':\n",
    "        return image.convert('RGB')\n",
    "    return image\n",
    "\n",
    "content_tf = train_transform()\n",
    "style_tf = train_transform()\n",
    "color_tf = train_transform()\n",
    "\n",
    "content_dataset = FlatFolderDataset(args.content_dir, content_tf)\n",
    "style_dataset = FlatFolderDataset(args.style_dir, style_tf)\n",
    "color_dataset = FlatFolderDataset(args.color_dir, color_tf)\n",
    "\n",
    "print('create dataloader')\n",
    "content_iter = iter(data.DataLoader(\n",
    "    content_dataset, batch_size=args.batch_size,\n",
    "    sampler=InfiniteSamplerWrapper(content_dataset),\n",
    "    num_workers=args.n_threads))\n",
    "style_iter = iter(data.DataLoader(\n",
    "    style_dataset, batch_size=args.batch_size,\n",
    "    sampler=InfiniteSamplerWrapper(style_dataset),\n",
    "    num_workers=args.n_threads))\n",
    "color_iter = iter(data.DataLoader(\n",
    "    color_dataset, batch_size=args.batch_size,\n",
    "    sampler=InfiniteSamplerWrapper(color_dataset),\n",
    "    num_workers=args.n_threads))\n",
    "\n",
    "params = list(network.decoder.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=args.lr)\n",
    "\n",
    "print('start training')\n",
    "for i in tqdm(range(args.max_iter)):\n",
    "    adjust_learning_rate(optimizer, iteration_count=i)\n",
    "    content_images = next(content_iter).to(device)\n",
    "    style_images = next(style_iter).to(device)\n",
    "    color_images = next(color_iter).to(device)\n",
    "    loss_ct, loss_st, loss_cct, loss_sc = network(content_images, style_images, color_images)\n",
    "    loss_c = args.content_weight * (loss_ct)\n",
    "    loss_s = args.style_weight * (loss_st)\n",
    "    loss_cc = 1*loss_cct+ 2*(1/np.sqrt(2))*loss_sc\n",
    "    loss = loss_c + loss_s + loss_cc\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    writer.add_scalar('loss_content', loss_c.item(), i + 1)\n",
    "    writer.add_scalar('loss_style', loss_s.item(), i + 1)\n",
    "\n",
    "    if (i + 1) % args.save_model_interval == 0 or (i + 1) == args.max_iter:\n",
    "        state_dict = {\n",
    "            'decoder': network.decoder.state_dict(),\n",
    "        }\n",
    "        torch.save(state_dict, save_dir /\n",
    "                   'decoder_iter_{:d}.pth.tar'.format(i + 1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fdbaf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'his_mapping_network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5156/4004391713.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m state_dict = {\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0;34m'his_net'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhis_mapping_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         }\n\u001b[1;32m      4\u001b[0m torch.save(state_dict, save_dir /\n\u001b[1;32m      5\u001b[0m                    'his_net_iter_{:d}.pth.tar'.format(i + 1))\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1208\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'his_mapping_network'"
     ]
    }
   ],
   "source": [
    "state_dict = {\n",
    "            'his_net': network.his_mapping_network.state_dict(),\n",
    "        }\n",
    "torch.save(state_dict, save_dir /\n",
    "                   'his_net_iter_{:d}.pth.tar'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250385c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "his_mapping_network = HistVectorizer(64, 512, int(8))\n",
    "\n",
    "a = torch.rand(1, 3, 64, 64)\n",
    "\n",
    "b = his_mapping_network(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbafc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
